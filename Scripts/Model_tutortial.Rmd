---
title: "Model Tutorial"
author: "Eura Nama"
output:
  bookdown::word_document2:
    fig_caption: yes
    number_sections: false
  fontsize: 12pt
  sansfont: Liberation Sans
  mainfont: Liberation Sans
  classoption: twocolumn
  language: english
  #bookdown::html_document2: default
  # bookdown::pdf_document2:
  #     keep_tex: yes
  #     number_sections: false
  #     toc: no
  #     # includes:
  #     # in_header: "styling.sty"
  # language: english
  # classoption: twocolumn
header-includes: 
  - \usepackage{tikz} \usepackage{pdflscape} \usepackage{float}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
---


```{r setup, include=FALSE,echo=F, message=F,warning=F,cache=F}
options(scipen = 999) # Just forces numbers to not be in scientific notiation
# First up we will check your r packages and install anything you need for this for you.
req.packages <- c("tidyverse","lubridate","plotly","sf","sp","data.table","units","cowplot","knitr",'concaveman',
                  'ggthemes',"nngeo","marmap","RandomFields","ggplot2","stars","tmaptools","rnaturalearth",
                  "rnaturalearthdata","raster","rgdal","RStoolbox","pals","ggnewscale","ggspatial",'devtools','rlist','matlab','coda','rjags','R2jags')
# If you don't have the packages install them + give a heads up that you are
new.packages <- req.packages[!(req.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)>0) 
{
  cat(paste0("Heads up, I have to install these packages for this to work:", new.packages ))
  #wanna.install <- readline(prompt = "If you want to install these package(s) enter 'y': ")
  #if(tolower(wanna.install) == 'y') 
  install.packages(new.packages,repos = "http://cran.us.r-project.org") #else { stop("You didn't want to install the packages so this script does not work.")}
}

# You also need to install this github repo package if you do not have it.
hi.res <- any(installed.packages()[,"Package"] %in% "rnaturalearthhires")
if(hi.res == F) devtools::install_github("https://github.com/ropensci/rnaturalearthhires/")
  

# The libraries that we will use directly in this code
library(knitr)
library(ggplot2)
library(gridExtra)
library(reshape2)
library(scales)
library(cowplot)
library(tidyverse)
library(dplyr)
library(tidyr)
library(RandomFields)
library(sf)
library(marmap)
library(stars)
library(raster)
library(matlab)
library(R2jags)

knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
# Set the Workding directory.


#Some Custom Functions I'll need
funs <- c("https://raw.githubusercontent.com/Mar-Scal/Assessment_fns/master/Maps/pectinid_projector_sf.R",
          "https://raw.githubusercontent.com/Mar-scal/Assessment_fns/master/Maps/centre_of_gravity.R",
          "https://raw.githubusercontent.com/Mar-scal/Assessment_fns/master/Maps/add_alpha_function.R",
          "https://raw.githubusercontent.com/Mar-scal/Assessment_fns/master/Maps/combo_shp.R",
          "https://raw.githubusercontent.com/Dave-Keith/Assessment_fns/master/Maps/convert_coords.R",
          "https://raw.githubusercontent.com/Dave-Keith/Fisheries_module/master/Scripts/Functions/beta_dist_rand_num.R",
          "https://raw.githubusercontent.com/Dave-Keith/Fisheries_module/master/Scripts/Functions/function_to_call_beta_or_strected_beta_functions.R",
          "https://raw.githubusercontent.com/Dave-Keith/Fisheries_module/master/Scripts/Functions/Model_function.R",
          "https://raw.githubusercontent.com/Dave-Keith/Fisheries_module/master/Scripts/Functions/posterior_plot.R",
          "https://raw.githubusercontent.com/Dave-Keith/Fisheries_module/master/Scripts/Functions/stretched_beta_dist_rand_num_new.R")

# Now run through a quick loop to load each one, just be sure that your working directory is read/write!
for(fun in funs) 
{
  download.file(fun,destfile = basename(fun))
  source(paste0(getwd(),"/",basename(fun)))
  file.remove(paste0(getwd(),"/",basename(fun)))
}


  
# A couple custom functions I may or may not use
factor.2.number <- function(x) {as.numeric(levels(x))[x]} # My friend factor.2.number
# Function in case you need it for transforming propotion data to not have 0's and 1's.  
beta.transform <- function(dat,s=0.5)  (dat*(length(dat)-1) + s) / length(dat)
# Cute little function to divide split something up by a weighting factor.
nsplit = function(X,n)
{
  p = X/sum(X)
  diff(round(n*cumsum(c(0,p))))
}
# Now I want to make a bounding box that outlines our study area
survey.domain <- st_as_sf(data.frame(X = c(465000, 750000, 750000, 650000, 600000, 400000),
                                    Y = c(4450000,4450000,4710000,4900000,4860000,4800000),ID=1),coords = c("X","Y"),crs= 32619)
# Transform it to proper units
survey.domain <- st_transform(survey.domain,crs = 4326)
# And convert it from some points into a polygon object
survey.domain <- st_cast(st_combine(survey.domain),"POLYGON")

# Now we can carve up our survey domain into a bunch of grids, size is I believe 0.1 degrees, so 6 minutes each I think (10 per degree)
survey.grid <- st_make_grid(survey.domain,cellsize = 0.1)
# Then we clip that to the survey domain and we have some nice cells we can toss biomass into kinda almost anyway we'd like.
survey.grid <- st_intersection(survey.grid,survey.domain)
# Make this a nice sf object for later.
survey.grid <- st_sf(survey.grid)
survey.grid$strata <- 1:nrow(survey.grid)
# What is the total survey area
tot.area <- st_area(survey.grid) %>% units::set_units("km2") %>% as.numeric() %>% sum(na.rm=T)

# Lets grab the NAFO subareas that are going to form our survey domain, I'll need to tweak a few of them to cut off to the south of GB
# Figure out where your tempfiles are stored
temp <- tempfile()
# Download this to the temp directory you created above
download.file("https://raw.githubusercontent.com/Mar-scal/GIS_layers/master/NAFO/Subareas.zip", temp, quiet=T)
# Figure out what this file was saved as
temp2 <- tempfile()
# Unzip it
unzip(zipfile=temp, exdir=temp2)
# This pulls in all the layers from the above location
nafo <- combo.shp(temp2,make.sf=T, quiet=T)
nafo <- st_make_valid(nafo)
# Now clip the nafo strata into our made up survey domain
nafo.strata <- st_intersection(nafo,survey.domain)
nafo.strata
# Two of the strata kinda suck, id 125, 135, 141, and 142 are going to go as they aren't unique subareas.
nafo.strata <- nafo.strata %>% dplyr::filter(!id %in% c(125,135,141,142))
nafo.strata$strata <- nafo.strata$id
# Calculate the total area and the area by strata
nafo.strata$area <- st_area(nafo.strata) %>% units::set_units("km^2") %>% as.numeric()
tot.area <- sum(nafo.strata$area) # This gets the same number as using st_area(survey.domain) so this is the total area of the survey domain
# Now we calculate the proportion of the total area that each strata covers
nafo.strata$p.area <-nafo.strata$area/tot.area

```

```{r user-inputs, echo=F,message=F, warning=F}

# You can set the number of stations...
n.tows <- 20

# How do you want to set up the survey, Random Stratified or NAFO stratified
surv.dist <- c("Random","NAFO") 
# Which Biomass distribution do you want [1] will be Random Survey, 2 will be NAFO survey, and 3 will be "Depth
# Just comment and uncomment to shift between the options
#surv.dist <- surv.dist[1] # This is a random survey
surv.dist <- surv.dist[2] # This is a stratified survey using NAFO

# This changes the number of biomass simulations you run, I suggest trying 1, 4, and 250 (250 will be slow!) to see if it changes your opinion
n.sims <- 9

# You can change the area that is covered by each survey tow. This value is in m². The default value of 10,000 is equivalent to a 2 km survey tow that is 5 meters wide
# Changing this won't have as much impact as it might in real world as simulation of real world variability in densities would take hours, so we leave it 
# as a fixed number
area.swept.m <-  10000    # somewhere in the 1000's of square meters tends to make sense here for trawl kinds of gear.  Also need to convert to km²
# This too would have impacts on results if we had a more realistic biomass distribution scenario, but in this world we will leave it as is.
tot.biomass <- 100000 # Could be any units, let's call it tonnes, and because of how I have this set up below this number isn't exact
rec.biomass <- 30000 # So I think it'll be easier to just assume we have a recruitment index and treat it like the biomass (but give it it a unique RF too)
# Catchability could also be allowed to vary spatially, but that adds a layer of complexity that is beyond the scope of this exercise, so 
# changing this won't really do anything other than rescale the biomass per tow and survey biomass estimates.
catchability <- 0.3 # What proportion of the population does survey tend to catch, going to fix this at 0.3 for simplicity


# Set your priors for q and m, you will get a plot showing the properties of this prior in the output. 
q.prior <- data.frame(a=15,b=35)
m.prior <- data.frame(a=7,b=55)
# Quick guide... if a < b your mode for the prior will be < 0.5, if a = b it'll be around 0.5, if a > b it'll be > 0.5
# the a/b ratio controls distance from 0.5.  
# The size of a and b controls the width of the distributions, if a and b are low you get a very wide distributions
# If a and b are high you get more narrow distributions.  
#Play around with this command to experiment on different shapes of the beta distribution  
#hist(rbeta(10000,5,1))

niter <- 2000 # When initially exploring your results, keep this around 2000 so the model runs quickly, increase to 20000 for final runs of your models

```

```{r paras-table, echo=F}

# Now some derived parameters based on the area we are studying and the inputs provided at the top.
m2.to.km2 <- 1e-6 # convert from m2 to km2
area.swept <- area.swept.m*m2.to.km2 # Convert area swept by each tow into km²
#mn.bm.dens <- tot.biomass/tot.area# The mean biomass density in the region
tot.towable.area <- tot.area / area.swept # This is the total possible number of tows one could do in the entire area.
#expected.bm.per.tow <- tot.biomass/tot.area*area.swept*1000*catchability # This is what we should expect to be the biomass per tow in KG given the above inputs.
#expect.survey.bm <- tot.biomass*catchability # This is what the biomass from the survey should be given the catchability.


# Let's get all the parameters formatted nicely for a table so we can see them
input.paras <- data.frame(Parameter = c("Number of Tows ", 
                                       "Catchability",
                                       "Area swept by a tow",
                                       "Number of Simulations",
                                       "Survey Design"),
                         Value     = c( n.tows,
                                        catchability,
                                        paste(area.swept.m,"m²"),
                                        n.sims,
                                        surv.dist))

knitr::kable(input.paras,booktabs=T, caption = "A Table of your input values for the current run of your simulation")
```



```{r rand-field,echo=F,message=F,warning=F}
# So there are 1399 points, so this returns it all in one big smoogle that we need to extract ourselves.
# It appears that there is some auto-regressive component to the field as there is correlation through time.
yrs <- 1990:2021
n.years <- length(yrs)

centroids <- st_centroid(survey.grid)# %>% data.frame()
cent.split <- centroids %>% dplyr::summarise(lat = unlist(map(centroids$survey.grid,1)),
                                      long = unlist(map(centroids$survey.grid,2)))

# Now simulate the field.
gmrfs <- RFsimulate(model = RMgauss(var=0.1, scale =1), x=cent.split$lat, y=cent.split$long, grid =F, T = yrs)
rec.gmrfs <- RFsimulate(model = RMgauss(var=0.2, scale =0.5), x=cent.split$lat, y=cent.split$long, grid =F, T = yrs)
# Make it an SF object
gmrfs.sf <- st_as_sf(gmrfs, crs = 4326)
rec.gmrfs.sf <- st_as_sf(rec.gmrfs, crs = 4326)
# This extracts the year data from the SP object which we bind to our data.
gmrfs.sf$years <- gmrfs@coords[,3]
st_crs(gmrfs.sf) <- 4326
rec.gmrfs.sf$years <- rec.gmrfs@coords[,3]
st_crs(rec.gmrfs.sf) <- 4326
# ggplot(gmrfs.sf) + geom_sf(aes(fill = variable1,color=variable1),size=3) + scale_fill_viridis_b() + scale_color_viridis_b() + facet_wrap(~years)
# ggplot(rec.gmrfs.sf) + geom_sf(aes(fill = variable1,color=variable1),size=3) + scale_fill_viridis_b() + scale_color_viridis_b() + facet_wrap(~years)
```


So we have a method to generate random fields (or a bunch of them if we want) so now I want to make our model

```{r B-sim, echo=F,message=F, warning=F}

# Set up or parameters, this seems like a pretty stable set of parameters
m.mn   <- 0.2
g.mn   <- 1.1
gr.mn <- 1.4
E.mn  <- 0.15
B <- tot.biomass # The initial B
R.mn <- rec.biomass # The average number of recruits over time period

C <- NA # The catch
B.tmp <- NA # Initializing the Biomass, this is an intermediate B value
R.samp <- betaset('st.beta',R.mn,R.mn^2,0,1e6)
m.samp <- betaset('beta',m.mn,0.005,0.1,0.4)
E.samp <- betaset('beta',E.mn,0.005,0.1,0.4)
G.samp <- betaset('st.beta',g.mn,0.005,0.5,2)
GR.samp <- betaset('st.beta',gr.mn,0.01,1,2.5)

# Now I can run some simulations....

for(s in 1:n.sims)
{

R <- sample(R.samp,n.years,replace=T)
E <- sample(E.samp,n.years,replace=T)
M <- sample(m.samp,n.years,replace=T)

G <- sample(G.samp,n.years,replace=T)
GR <- sample(GR.samp,n.years,replace=T)

for(i in 1:n.years)
{
  if(i == 1) 
  {
    # Here we are handling catch and biomass a bit differently then below, in first year we set the biomass and then remove the catch from that
    # This is really just being done to get a year '0' catch and biomass, might not even use this in the end, we'll see
    C[i] <- B[i] * E[i]
  }
    
  if(i > 1)
  {
    B.tmp[i] <- (B[i-1])*exp(-M[i])*G[i] + R[i-1]*exp(-M[i])*GR[i]
    C[i] <-  B.tmp[i] * E[i]
    B[i] <- B.tmp[i] -C[i]
    
  }

}}# end the for loops

mod.actual <- data.frame(biomass = B,
                         catch = C,
                         exploitation.rate = E,
                         natural.mort = M,
                         growth.adults = G,
                         recruits  = R,
                         growth.recruits = GR,
                         years = yrs
                         )

```

Here I am distributing the biomass across the area according to the GMRF. 

```{r B-distribute, echo=F,message=F, warning=F}


# Get the biomass distribution across the area
bm.dat <- data.frame(years = yrs, 
                     tot.biomass = mod.actual$biomass,mn.bm.dens = mod.actual$biomass/tot.area)

gmrfs.bm <- st_join(survey.grid,gmrfs.sf)
gmrfs.bm <- left_join(gmrfs.bm,bm.dat,by="years")
# Now we spread the biomass across the area based on the random field.
gmrfs.bm$bm.dens <- exp(log(gmrfs.bm$mn.bm.dens) + gmrfs.bm$variable1)
# And have fun calculating biomasses
gmrfs.bm$grid.area <- gmrfs.bm %>% st_area() %>% units::set_units("km^2") %>% as.numeric()
gmrfs.bm$biomass.cell <- gmrfs.bm$grid.area*gmrfs.bm$bm.dens
gmrfs.bm <- gmrfs.bm %>% dplyr::group_by(years) %>% dplyr::mutate(tmp.biomass = sum(biomass.cell))
# Now we adjust it back to our initial biomass
gmrfs.bm$biomass.cell <- gmrfs.bm$biomass.cell*gmrfs.bm$tot.biomass/gmrfs.bm$tmp.biomass
gmrfs.bm$bm.dens <- gmrfs.bm$biomass.cell/gmrfs.bm$grid.area

# Now repeat the same things for the recruit field
rec.dat <- data.frame(years = yrs, 
                      tot.biomass = mod.actual$recruits,mn.bm.dens = mod.actual$recruits/tot.area)

gmrfs.rec <- st_join(survey.grid,rec.gmrfs.sf)
gmrfs.rec <- left_join(gmrfs.rec,rec.dat,by="years")

gmrfs.rec$bm.dens <- exp(log(gmrfs.rec$mn.bm.dens) + gmrfs.rec$variable1)

gmrfs.rec$grid.area <- gmrfs.rec %>% st_area() %>% units::set_units("km^2") %>% as.numeric()
gmrfs.rec$biomass.cell <- gmrfs.rec$grid.area*gmrfs.rec$bm.dens
gmrfs.rec <- gmrfs.rec %>% dplyr::group_by(years) %>% dplyr::mutate(tmp.biomass = sum(biomass.cell))
# Now we adjust it back to our initial biomass
gmrfs.rec$biomass.cell <- gmrfs.rec$biomass.cell*gmrfs.rec$tot.biomass/gmrfs.rec$tmp.biomass
gmrfs.rec$bm.dens <- gmrfs.rec$biomass.cell/gmrfs.rec$grid.area


bm.res <- gmrfs.bm
rec.res <- gmrfs.rec

# ggplot(gmrfs.rec) + geom_sf(aes(fill = bm.dens,color=bm.dens)) + scale_fill_viridis_b() + scale_color_viridis_b() + facet_wrap(~years)
# ggplot(gmrfs.rec) + geom_sf(aes(fill = variable1,color=variable1)) + scale_fill_viridis_b() + scale_color_viridis_b() + facet_wrap(~years)
# ggplot(gmrfs.bm) + geom_histogram(aes(x=bm.dens))  + facet_wrap(~years)
# gmrfs.rec %>% dplyr::group_by(years) %>% dplyr::summarize(sum = sum(biomass.cell))
```

So now we should sample from our area. Given last weeks results we will use both a random sample of the area each year and a stratified survey using the NAFO grid.  Let's see if one does better than the other at this.

```{r sample-B, echo=F,message=F, warning=F}


samp.bm.tmp <- NULL
samp.rec.tmp <- NULL
surv.tmp <- NULL
rec.est.tmp <- NULL
bm.est.tmp <- NULL

# Now we generate a different sample each year, so repeat this n.years times
for(i in 1:n.years) 
{
  
  # This years biomass fields...
  bm.tmp <- bm.res %>% dplyr::filter(years == yrs[i])
  rec.tmp <- rec.res %>% dplyr::filter(years == yrs[i])
  
  if(surv.dist == "NAFO")
  {
    nafo.strata$years <- yrs[i]
    nafo.strata$stations <- nsplit(nafo.strata$p.area, n.tows) 
    # Now calculate the area swept in each of the areas, use a few metrics here
    nafo.strata <- nafo.strata %>% dplyr::mutate(area.surveyed = stations * area.swept,
                                             towable.area = area/area.swept)

    surv.tmp[[i]] <- nafo.strata
    # Now we can sample from the above each year, want this to be the same for recruits and biomass
    samp.bm.tmp[[i]] <- samp.rec.tmp[[i]] <- st_sample(surv.tmp[[i]], size = nafo.strata$stations,type = 'random', exact = T) %>%
                          st_sf('ID' = seq(length(.)), 'geometry' = .) %>%
                          st_intersection(., nafo.strata)
    
    # Now combo with the biomass data
    samp.bm.tmp[[i]] <- st_join(samp.bm.tmp[[i]],bm.tmp %>% dplyr::select(!strata))
    
    samp.bm.tmp[[i]]$sample.bm.per.tow <- rlnorm(n.tows,log(catchability*samp.bm.tmp[[i]]$bm.dens*area.swept*1000),0.25)
    # Biomass density in kg/km^2
    samp.bm.tmp[[i]]$sample.bm.dens <- samp.bm.tmp[[i]]$sample.bm.per.tow/area.swept
    # Now things get much more complex as we have to get stratified estimates.
    #First we get the mean for each strata, the 'id' field is strata at the moment
    strata.res <- samp.bm.tmp[[i]] %>% dplyr::group_by(strata,area,p.area,stations,area.surveyed,towable.area) %>% 
                                    dplyr::summarise(mn.ptow = mean(sample.bm.per.tow),
                                                     var.ptow = var(sample.bm.per.tow))
    # Now we take these strata means and account for the area in each strata.  This is the biomass per tow
    strata.res  <- strata.res %>% dplyr::mutate(mn.pt.by.pa = mn.ptow*p.area)
    bm.per.tow <- sum(strata.res$mn.pt.by.pa)
    # Calculate the survey standard error.  In words... The Total number of towable units in a strata * difference 
    # So all the area calculations are done in 1a and 2a, then we multiply by the variance, then we have to divide by the number of stations
    se.calc.1 <- ((strata.res$area * (strata.res$area-strata.res$area.surveyed))) # Total area * Total area not surveyed
    se.calc.2 <- se.calc.1/sum(strata.res$area)^2 # Now we divide the above by the total area squared.  
    se.calc.3 <- se.calc.2 * strata.res$var.ptow # Then we multiply that by the variance 
    se.survey <- sum(se.calc.3/strata.res$stations,na.rm=T)^0.5 # then we divide this total by the number of stations, add up that number and take square root.
      
    # Now we need to know the difference between the area towed and the possible area towed, needed to figure out DF later...
    #ah <- (strata.res$towable.area * (strata.res$towable.area - strata.res$stations))/strata.res$stations
    area.df <- (strata.res$area * (strata.res$area - strata.res$area.surveyed))/strata.res$area.surveyed
    # Degrees of freedom
    df <- (sum(area.df * strata.res$var.ptow, na.rm = TRUE)^2)/(sum(((area.df * strata.res$var.ptow)^2)/(strata.res$stations - 1), na.rm = TRUE))
    # And the size of our CI around the mean estimate (95% CI)
    ci.per.tow <- bm.per.tow + (c(qt(0.05/2, df), -qt(0.05/2, df)) * se.survey)
    # Now scale up to whole bank, all these calculations are done per tow, so how many 'tows' could one do in the whole region?
    bm.tot <- bm.per.tow*tot.towable.area /1000 # Note we are in kg/tow, reset to tonnes for whole bank
    ci.tot <- ci.per.tow * tot.towable.area /1000 # Note we are in kg/tow, reset to tonnes for whole bank
    # Q-corrected
    bm.tot.q.cor <- bm.tot/catchability
    ci.tot.q.cor <- ci.tot/catchability
    # Put it into a dataframe
    bm.est.tmp[[i]] <- data.frame(biomass = c(bm.per.tow,bm.tot,bm.tot.q.cor),
                           lci = c(min(ci.per.tow),min(ci.tot),min(ci.tot.q.cor)),
                           uci = c(max(ci.per.tow),max(ci.tot),max(ci.tot.q.cor)),
                           metric = c("Per Tow","Survey","Q-Corrected"),
                           survey = rep('NAFO Strata',3),
                           simulation = rep(i,3),
                           years = yrs[i])
    # Now do the same thing to get the recruit biomass estimates from the survey
    samp.rec.tmp[[i]] <- st_join(samp.rec.tmp[[i]],bm.tmp %>% dplyr::select(!strata))
    
    samp.rec.tmp[[i]]$sample.bm.per.tow <- rlnorm(n.tows,log(catchability*samp.rec.tmp[[i]]$bm.dens*area.swept*1000),0.25)
    # Biomass density in kg/km^2
    samp.rec.tmp[[i]]$sample.bm.dens <- samp.rec.tmp[[i]]$sample.bm.per.tow/area.swept
    # Now things get much more complex as we have to get stratified estimates.
    #First we get the mean for each strata, the 'id' field is strata at the moment
    strata.res <- samp.rec.tmp[[i]] %>% dplyr::group_by(strata,area,p.area,stations,area.surveyed,towable.area) %>% 
                                    dplyr::summarise(mn.ptow = mean(sample.bm.per.tow),
                                                     var.ptow = var(sample.bm.per.tow))
    # Now we take these strata means and account for the area in each strata.  This is the biomass per tow
    strata.res  <- strata.res %>% dplyr::mutate(mn.pt.by.pa = mn.ptow*p.area)
    bm.per.tow <- sum(strata.res$mn.pt.by.pa)
    # Calculate the survey standard error.  In words... The Total number of towable units in a strata * difference 
    # So all the area calculations are done in 1a and 2a, then we multiply by the variance, then we have to divide by the number of stations
    se.calc.1 <- ((strata.res$area * (strata.res$area-strata.res$area.surveyed))) # Total area * Total area not surveyed
    se.calc.2 <- se.calc.1/sum(strata.res$area)^2 # Now we divide the above by the total area squared.  
    se.calc.3 <- se.calc.2 * strata.res$var.ptow # Then we multiply that by the variance 
    se.survey <- sum(se.calc.3/strata.res$stations,na.rm=T)^0.5 # then we divide this total by the number of stations, add up that number and take square root.
      
    # Now we need to know the difference between the area towed and the possible area towed, needed to figure out DF later...
    #ah <- (strata.res$towable.area * (strata.res$towable.area - strata.res$stations))/strata.res$stations
    area.df <- (strata.res$area * (strata.res$area - strata.res$area.surveyed))/strata.res$area.surveyed
    # Degrees of freedom
    df <- (sum(area.df * strata.res$var.ptow, na.rm = TRUE)^2)/(sum(((area.df * strata.res$var.ptow)^2)/(strata.res$stations - 1), na.rm = TRUE))
    # And the size of our CI around the mean estimate (95% CI)
    ci.per.tow <- bm.per.tow + (c(qt(0.05/2, df), -qt(0.05/2, df)) * se.survey)
    # Now scale up to whole bank, all these calculations are done per tow, so how many 'tows' could one do in the whole region?
    bm.tot <- bm.per.tow*tot.towable.area /1000 # Note we are in kg/tow, reset to tonnes for whole bank
    ci.tot <- ci.per.tow * tot.towable.area /1000 # Note we are in kg/tow, reset to tonnes for whole bank
    # Q-corrected
    bm.tot.q.cor <- bm.tot/catchability
    ci.tot.q.cor <- ci.tot/catchability
    # Put it into a dataframe
    rec.est.tmp[[i]] <- data.frame(biomass = c(bm.per.tow,bm.tot,bm.tot.q.cor),
                           lci = c(min(ci.per.tow),min(ci.tot),min(ci.tot.q.cor)),
                           uci = c(max(ci.per.tow),max(ci.tot),max(ci.tot.q.cor)),
                           metric = c("Per Tow","Survey","Q-Corrected"),
                           survey = rep('NAFO Strata',3),
                           simulation = rep(i,3),
                           years = yrs[i])
  } # end if "NAFO"
  
  
  if(surv.dist == "Random")
  {
    # And we can get our random sample each year
    surv.tmp[[i]] <- survey.domain %>% st_sample(size = n.tows) %>% st_sf()
    surv.tmp[[i]]$id <- 1:n.tows
    
    # Now do the biomass of adults
    samp.bm.tmp[[i]] <- st_join(surv.tmp[[i]],bm.tmp)
    # Also add the years to the random sample list
    samp.bm.tmp[[i]]$years <- yrs[i]
    # This is biomass in KG at the moment, just to make it make more sense.  Note the order of magnitude difference between the size of the stock and how many
    # are caught in this survey
    samp.bm.tmp[[i]]$sample.bm <- rlnorm(n.tows,log(catchability*  samp.bm.tmp[[i]]$bm.dens*area.swept*1000),0.25)
    # ggplot() + geom_sf(data = rand.samp.dat, aes(fill = sample.bm,color=sample.bm)) + 
    #            geom_sf(data=survey.domain, fill = NA) +
    #            scale_fill_viridis_b() + scale_color_viridis_b()
    
    # Now from here we use standard survey math to get a survey estimated biomass.  Steal from Stephens Simple survey code because i know that is done right :-)
    # The basic calculations for this are very straightforward, the average biomass per tow along with uncertainies
    bm.per.tow <- mean(  samp.bm.tmp[[i]]$sample.bm)
    se.per.tow <- sd(  samp.bm.tmp[[i]]$sample.bm)/sqrt(n.tows)
    # Our DF here is the number of stations
    ci.per.tow <- bm.per.tow + (c(qt(0.05/2, n.tows), -qt(0.05/2, n.tows)) * se.per.tow)
    
    # Alternatively, we just immediately can scale up to total area..
    bm.tot <- bm.per.tow* tot.towable.area /1000
    ci.tot <- ci.per.tow* tot.towable.area /1000
    
    # And here is our 'q corrected' survey biomass estimate from the random survey.
    bm.tot.q.cor <- bm.tot/catchability
    ci.tot.q.cor <- ci.tot/catchability
    bm.est.tmp[[i]] <- data.frame(biomass = c(bm.per.tow,bm.tot,bm.tot.q.cor),
                           lci = c(min(ci.per.tow),min(ci.tot),min(ci.tot.q.cor)),
                           uci = c(max(ci.per.tow),max(ci.tot),max(ci.tot.q.cor)),
                           metric = c("Per Tow","Survey","Q-Corrected"),
                           survey = rep('Random',3),
                           simulation = rep(i,3),
                           years = yrs[i])
    
    
    # Now for the recruits
    samp.rec.tmp[[i]] <- st_join(surv.tmp[[i]],rec.tmp)
    # Also add the years to the random sample list
    samp.rec.tmp[[i]]$years <- yrs[i]
    # This is biomass in KG at the moment, just to make it make more sense.  Note the order of magnitude difference between the size of the stock and how many
    # are caught in this survey
    samp.rec.tmp[[i]]$sample.bm <- rlnorm(n.tows,log(catchability*  samp.rec.tmp[[i]]$bm.dens*area.swept*1000),0.25)
    # ggplot() + geom_sf(data = rand.samp.dat, aes(fill = sample.bm,color=sample.bm)) + 
    #            geom_sf(data=survey.domain, fill = NA) +
    #            scale_fill_viridis_b() + scale_color_viridis_b()
    
    # Now from here we use standard survey math to get a survey estimated biomass.  Steal from Stephens Simple survey code because i know that is done right :-)
    # The basic calculations for this are very straightforward, the average biomass per tow along with uncertainies
    bm.per.tow <- mean(  samp.rec.tmp[[i]]$sample.bm)
    se.per.tow <- sd(  samp.rec.tmp[[i]]$sample.bm)/sqrt(n.tows)
    # Our DF here is the number of stations
    ci.per.tow <- bm.per.tow + (c(qt(0.05/2, n.tows), -qt(0.05/2, n.tows)) * se.per.tow)
    
    # Alternatively, we just immediately can scale up to total area..
    bm.tot <- bm.per.tow* tot.towable.area /1000
    ci.tot <- ci.per.tow* tot.towable.area /1000
    
    # And here is our 'q corrected' survey biomass estimate from the random survey.
    bm.tot.q.cor <- bm.tot/catchability
    ci.tot.q.cor <- ci.tot/catchability
    rec.est.tmp[[i]] <- data.frame(biomass = c(bm.per.tow,bm.tot,bm.tot.q.cor),
                           lci = c(min(ci.per.tow),min(ci.tot),min(ci.tot.q.cor)),
                           uci = c(max(ci.per.tow),max(ci.tot),max(ci.tot.q.cor)),
                           metric = c("Per Tow","Survey","Q-Corrected"),
                           survey = rep('Random',3),
                           simulation = rep(i,3),
                           years = yrs[i])
    
  } # End if == "Random"

}

surv.dat <- do.call("rbind",surv.tmp)
samp.bm.dat <- do.call("rbind",samp.bm.tmp)
samp.rec.dat <- do.call("rbind",samp.bm.tmp)
bm.est.dat <- do.call("rbind",bm.est.tmp)
rec.est.dat <- do.call("rbind",rec.est.tmp)
# Note that we can get negative values for the LCI because we are assuming the bm.per.tow is normally distributed.  These are truncated to 0's here.
bm.est.dat$lci[bm.est.dat$lci <0] <- 0

```

The final? step is to take the survey results and then plug those into a model to see how we do.  We can estimate biomass, but we don't actually have
any real data on catchability, recruitment, natural mortality, or growth rates, so we have to make assumptions about those.  All we really know is
biomass and removals.


```{r mod-priors,echo=F,message=F,warning=F,fig.cap = "The Prior distributions for catchability and mortality"}


priors <- data.frame(res = c(rbeta(10000,q.prior$a,q.prior$b),rbeta(10000,m.prior$a,m.prior$b)),
                     dist = c(rep("Catchibility Prior",10000),rep("Natural Mortality Prior",10000)))

# Now make a plot of the priors
plt.pr <- ggplot(priors) + geom_freqpoly(aes(x= res)) + facet_wrap(~dist) + theme_bw()
plt.pr

```


```{r mod-params, echo=F,message=F, warning=F}

mod.dat <- data.frame(I = bm.est.dat %>% dplyr::filter(metric == "Survey") %>% dplyr::select(biomass) %>% unname(), 
                      IR = rec.est.dat %>% dplyr::filter(metric == "Survey") %>% dplyr::select(biomass) %>% unname(),
                      G = mod.actual$growth.adults,
                      GR = mod.actual$growth.recruits,
                      C = mod.actual$catch,
                      year = yrs)

# Load in the model function

# Don't touch these...
r.prior = data.frame(a=rec.biomass,b=1000)
b0.prior= data.frame(a=tot.biomass,b=0.5)

# Run the model
res <- run_model(mod.dat = mod.dat, nchains=6,niter = niter,nburn = 0.25*n.iter,
          m.prior = m.prior,q.prior = q.prior,
          r.prior = r.prior, b0.prior = b0.prior)

mod.res <- data.frame(biomass = DD.out$median$B,
                      recruits = DD.out$median$R,
                      exploitation.rate = DD.out$median$mu,
                      years = yrs)

# Some model outputs needed for the Update.  First the mortality
mort <- 1- exp(-DD.out$mean$m)

  # Here we can grab the Fully recruited and recruit biomass for the last 2 years and the median of the time series.
FR.bm <- DD.out$median$B
# We exclude the current year from the median estimate
FR.ltm <- median(DD.out$median$B[-length(DD.out$median$B)])
# Recruit biomass
rec.bm <- DD.out$median$R
# We exclude the current year from the median estimate
rec.ltm <- median(DD.out$median$R[-length(DD.out$median$R)])
# Get the posterior and priors for q and M
q.post <- data.frame(Posterior = DD.out$sims.list$q, Prior = rbeta(length(DD.out$sims.list$q),q.prior$a,q.prior$b))
m.post <- data.frame(Posterior = DD.out$sims.list$M, Prior = rbeta(length(DD.out$sims.list$M),m.prior$a,m.prior$b))


# Here are the main output plots that should summarize everything that needs summarized for this
ggplot(q.post) + geom_histogram(aes(Posterior)) + geom_freqpoly(aes(Prior)) + xlab("Catchability") + ylab("")
ggplot(m.post) + geom_histogram(aes(Posterior)) + geom_freqpoly(aes(Prior)) + xlab("Natural Mortality") + ylab("")

  
ggplot(mod.actual) + geom_line(aes(x=years,y=natural.mort),size=1.5,color='blue') + 
                     geom_hline(aes(yintercept = DD.out$median$M),size=1.5,linetype='dashed',color='darkgrey') + theme_bw()
  
ggplot(mod.actual) + geom_point(aes(x=years,y=biomass),size=1.5,color='blue') + 
                     geom_line(data = mod.res,aes(y=biomass,x=years),size=1.5,color='darkgrey') + theme_bw()
  
ggplot(mod.actual) + geom_point(aes(x=years,y=recruits),size=1.5,color='blue') + 
                     geom_line(data = mod.res,aes(y=recruits,x=years),size=1.5,color='darkgrey') + theme_bw()
  
ggplot(mod.actual) + geom_point(aes(x=years,y=exploitation.rate),size=1.5,color='blue') + 
                     geom_line(data = mod.res,aes(y=exploitation.rate,x=years),size=1.5,color='darkgrey') + theme_bw()
  
  
```